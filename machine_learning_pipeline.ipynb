{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Disease Prediction ML Pipeline\n",
    "\n",
    "This notebook implements a complete machine learning pipeline for heart disease prediction using the UCI Heart Disease dataset. The pipeline includes data loading, preprocessing, feature engineering, model training, evaluation, and prediction capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Database libraries\n",
    "import os\n",
    "from sqlalchemy import create_engine, Column, Integer, Float, String, DateTime, Text, Boolean\n",
    "from sqlalchemy.orm import declarative_base, sessionmaker\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Utility libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Database Setup (Optional)\n",
    "\n",
    "Setup database schema for experiment tracking and prediction logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database setup\n",
    "Base = declarative_base()\n",
    "\n",
    "class ExperimentRun(Base):\n",
    "    __tablename__ = 'experiment_runs'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    timestamp = Column(DateTime, default=datetime.utcnow)\n",
    "    dataset_samples = Column(Integer)\n",
    "    train_samples = Column(Integer)\n",
    "    val_samples = Column(Integer)\n",
    "    test_samples = Column(Integer)\n",
    "    val_accuracy = Column(Float)\n",
    "    test_accuracy = Column(Float)\n",
    "    model_params = Column(Text)  # JSON string\n",
    "    feature_importance = Column(Text)  # JSON string\n",
    "\n",
    "class Prediction(Base):\n",
    "    __tablename__ = 'predictions'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    timestamp = Column(DateTime, default=datetime.utcnow)\n",
    "    experiment_id = Column(Integer)\n",
    "    input_features = Column(Text)  # JSON string\n",
    "    predicted_class = Column(Integer)\n",
    "    prediction_probability = Column(Float)\n",
    "    true_label = Column(Integer, nullable=True)\n",
    "    is_correct = Column(Boolean, nullable=True)\n",
    "\n",
    "def init_database():\n",
    "    \"\"\"Initialize database connection and create tables\"\"\"\n",
    "    try:\n",
    "        database_url = os.getenv('DATABASE_URL')\n",
    "        if not database_url:\n",
    "            print(\"Database URL not found. Skipping database setup.\")\n",
    "            return None\n",
    "        \n",
    "        engine = create_engine(database_url)\n",
    "        Base.metadata.create_all(engine)\n",
    "        Session = sessionmaker(bind=engine)\n",
    "        return Session()\n",
    "    except Exception as e:\n",
    "        print(f\"Database connection failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Initialize database session\n",
    "db_session = init_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Overview\n",
    "\n",
    "Load the Heart Disease dataset from UCI ML Repository and display basic information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    \"\"\"Load the Heart Disease dataset from UCI ML Repository\"\"\"\n",
    "    try:\n",
    "        from ucimlrepo import fetch_ucirepo\n",
    "        \n",
    "        print(\"Loading Heart Disease dataset from UCI ML Repository...\")\n",
    "        heart_disease = fetch_ucirepo(id=45)\n",
    "        X = heart_disease.data.features\n",
    "        y = heart_disease.data.targets\n",
    "        \n",
    "        # Combine features and target into a single DataFrame\n",
    "        df = X.copy()\n",
    "        df['target'] = y\n",
    "        \n",
    "        print(\"‚úÖ Dataset loaded successfully!\")\n",
    "        return df, heart_disease\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading dataset: {str(e)}\")\n",
    "        print(\"üí° Make sure you have the 'ucimlrepo' package installed: pip install ucimlrepo\")\n",
    "        return None, None\n",
    "\n",
    "# Load the dataset\n",
    "df, heart_disease_info = load_dataset()\n",
    "\n",
    "if df is not None:\n",
    "    print(f\"\\nDataset shape: {df.shape}\")\n",
    "    print(f\"Features: {df.shape[1] - 1}\")\n",
    "    print(f\"Samples: {df.shape[0]}\")\n",
    "    print(f\"Target classes: {df['target'].nunique()}\")\n",
    "    print(f\"Missing values: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "if df is not None:\n",
    "    print(\"First 5 rows of the dataset:\")\n",
    "    display(df.head())\n",
    "    \n",
    "    print(\"\\nDataset info:\")\n",
    "    df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Descriptive Statistics and Data Exploration\n",
    "\n",
    "Analyze the dataset characteristics and visualize the data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Basic statistics\n",
    "    print(\"Numerical Features Statistics:\")\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    display(df[numeric_cols].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Target distribution\n",
    "    target_counts = df['target'].value_counts()\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Pie chart\n",
    "    ax1.pie(target_counts.values, labels=target_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "    ax1.set_title('Target Distribution')\n",
    "    \n",
    "    # Bar chart\n",
    "    target_counts.plot(kind='bar', ax=ax2, color=['#ff6b6b', '#4ecdc4'])\n",
    "    ax2.set_title('Target Class Counts')\n",
    "    ax2.set_xlabel('Target Class')\n",
    "    ax2.set_ylabel('Count')\n",
    "    ax2.tick_params(axis='x', rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Feature correlations\n",
    "    correlation_matrix = df[numeric_cols].corr()\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='RdBu', center=0, \n",
    "                square=True, fmt='.2f', cbar_kws={'shrink': 0.8})\n",
    "    plt.title('Feature Correlation Heatmap')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering\n",
    "\n",
    "Apply feature transformations and create new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_feature_engineering(df):\n",
    "    \"\"\"Apply feature engineering transformations\"\"\"\n",
    "    if df is None:\n",
    "        return None\n",
    "    \n",
    "    print(\"Applying Feature Engineering...\")\n",
    "    \n",
    "    # Handle missing values\n",
    "    missing_before = df.isnull().sum().sum()\n",
    "    if missing_before > 0:\n",
    "        print(f\"‚ö†Ô∏è Found {missing_before} missing values. Filling with median values for numerical columns.\")\n",
    "        df_clean = df.copy()\n",
    "        numeric_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "        df_clean[numeric_cols] = df_clean[numeric_cols].fillna(df_clean[numeric_cols].median())\n",
    "    else:\n",
    "        print(\"‚úÖ No missing values found!\")\n",
    "        df_clean = df.copy()\n",
    "    \n",
    "    # Feature engineering: Create chol_age_ratio\n",
    "    print(\"Creating new feature: Cholesterol-to-Age Ratio\")\n",
    "    \n",
    "    if 'chol' in df_clean.columns and 'age' in df_clean.columns:\n",
    "        df_clean['chol_age_ratio'] = df_clean['chol'] / df_clean['age']\n",
    "        print(\"‚úÖ Created 'chol_age_ratio' feature\")\n",
    "        \n",
    "        print(f\"Mean Ratio: {df_clean['chol_age_ratio'].mean():.2f}\")\n",
    "        print(f\"Std Ratio: {df_clean['chol_age_ratio'].std():.2f}\")\n",
    "    else:\n",
    "        print(\"‚ùå Required columns 'chol' and 'age' not found for feature engineering\")\n",
    "        return df_clean\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Apply feature engineering\n",
    "df_engineered = apply_feature_engineering(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_engineered is not None and 'chol_age_ratio' in df_engineered.columns:\n",
    "    # Visualize the new feature\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(df_engineered['chol_age_ratio'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    plt.title('Distribution of Cholesterol-to-Age Ratio')\n",
    "    plt.xlabel('Cholesterol-to-Age Ratio')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Outlier Removal\n",
    "\n",
    "Remove outliers based on quantile threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_outlier_removal(df, outlier_threshold=0.05):\n",
    "    \"\"\"Remove outliers based on quantile threshold\"\"\"\n",
    "    if df is None:\n",
    "        return None\n",
    "    \n",
    "    print(\"Applying Outlier Removal...\")\n",
    "    \n",
    "    if 'chol_age_ratio' not in df.columns:\n",
    "        print(\"‚ùå 'chol_age_ratio' column not found. Please apply feature engineering first.\")\n",
    "        return df\n",
    "    \n",
    "    # Calculate quantile threshold\n",
    "    q_threshold = df['chol_age_ratio'].quantile(outlier_threshold)\n",
    "    \n",
    "    # Remove outliers\n",
    "    df_filtered = df[df['chol_age_ratio'] >= q_threshold].copy()\n",
    "    \n",
    "    removed_count = len(df) - len(df_filtered)\n",
    "    \n",
    "    print(f\"Original Samples: {len(df)}\")\n",
    "    print(f\"Removed Outliers: {removed_count}\")\n",
    "    print(f\"Remaining Samples: {len(df_filtered)}\")\n",
    "    \n",
    "    if removed_count > 0:\n",
    "        print(f\"‚úÖ Removed {removed_count} outliers (chol_age_ratio < {q_threshold:.2f})\")\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è No outliers removed with current threshold\")\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "# Apply outlier removal\n",
    "df_processed = apply_outlier_removal(df_engineered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_engineered is not None and df_processed is not None and 'chol_age_ratio' in df_engineered.columns:\n",
    "    # Visualize before and after outlier removal\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Before outlier removal\n",
    "    ax1.hist(df_engineered['chol_age_ratio'], bins=30, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "    ax1.set_title('Before Outlier Removal')\n",
    "    ax1.set_xlabel('Cholesterol-to-Age Ratio')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # After outlier removal\n",
    "    ax2.hist(df_processed['chol_age_ratio'], bins=30, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "    ax2.set_title('After Outlier Removal')\n",
    "    ax2.set_xlabel('Cholesterol-to-Age Ratio')\n",
    "    ax2.set_ylabel('Frequency')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Splitting\n",
    "\n",
    "Create train, validation, and test splits with proper scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_splits(df, train_size=0.7, val_size=0.15, test_size=0.15, random_state=42):\n",
    "    \"\"\"Create train, validation, and test splits\"\"\"\n",
    "    if df is None:\n",
    "        return None\n",
    "    \n",
    "    print(\"Creating Data Splits...\")\n",
    "    \n",
    "    # Validate split sizes\n",
    "    if abs(train_size + val_size + test_size - 1.0) > 0.001:\n",
    "        print(\"‚ùå Split sizes must sum to 1.0\")\n",
    "        return None\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df.drop('target', axis=1)\n",
    "    y = df['target']\n",
    "    \n",
    "    # First split: train vs temp (val + test)\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, \n",
    "        test_size=(val_size + test_size), \n",
    "        random_state=random_state, \n",
    "        stratify=y\n",
    "    )\n",
    "    \n",
    "    # Second split: validation vs test\n",
    "    relative_test_size = test_size / (val_size + test_size)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, \n",
    "        test_size=relative_test_size, \n",
    "        random_state=random_state, \n",
    "        stratify=y_temp\n",
    "    )\n",
    "    \n",
    "    # Display split information\n",
    "    print(f\"Training Set: {len(X_train)} samples ({len(X_train)/len(df)*100:.1f}%)\")\n",
    "    print(f\"Validation Set: {len(X_val)} samples ({len(X_val)/len(df)*100:.1f}%)\")\n",
    "    print(f\"Test Set: {len(X_test)} samples ({len(X_test)/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    # Scale the features\n",
    "    print(\"Scaling Features...\")\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Convert back to DataFrames for easier handling\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "    X_val_scaled = pd.DataFrame(X_val_scaled, columns=X_val.columns, index=X_val.index)\n",
    "    X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "    \n",
    "    print(\"‚úÖ Data splitting and scaling completed!\")\n",
    "    \n",
    "    return {\n",
    "        'X_train': X_train_scaled, 'X_val': X_val_scaled, 'X_test': X_test_scaled,\n",
    "        'y_train': y_train, 'y_val': y_val, 'y_test': y_test,\n",
    "        'scaler': scaler\n",
    "    }\n",
    "\n",
    "# Create data splits\n",
    "data_splits = create_data_splits(df_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_splits is not None:\n",
    "    # Show scaling effect on a sample feature\n",
    "    feature_to_show = data_splits['X_train'].columns[0]  # First feature\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Before scaling (using original data)\n",
    "    original_feature = df_processed.drop('target', axis=1)[feature_to_show]\n",
    "    ax1.hist(original_feature, bins=20, alpha=0.7, color='lightblue', edgecolor='black')\n",
    "    ax1.set_title(f'Before Scaling - {feature_to_show}')\n",
    "    ax1.set_xlabel(feature_to_show)\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # After scaling\n",
    "    ax2.hist(data_splits['X_train'][feature_to_show], bins=20, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "    ax2.set_title(f'After Scaling - {feature_to_show}')\n",
    "    ax2.set_xlabel(f'{feature_to_show} (scaled)')\n",
    "    ax2.set_ylabel('Frequency')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Training\n",
    "\n",
    "Train a Decision Tree model with configurable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data_splits, max_depth=None, min_samples_split=2, min_samples_leaf=1, random_state=42):\n",
    "    \"\"\"Train the Decision Tree model\"\"\"\n",
    "    if data_splits is None:\n",
    "        return None\n",
    "    \n",
    "    print(\"Training Model...\")\n",
    "    \n",
    "    # Initialize model with parameters\n",
    "    model = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(data_splits['X_train'], data_splits['y_train'])\n",
    "    \n",
    "    # Quick validation\n",
    "    y_pred_val = model.predict(data_splits['X_val'])\n",
    "    val_accuracy = accuracy_score(data_splits['y_val'], y_pred_val)\n",
    "    \n",
    "    print(\"‚úÖ Model training completed successfully!\")\n",
    "    print(f\"Model Type: Decision Tree Classifier\")\n",
    "    print(f\"Training Samples: {len(data_splits['X_train'])}\")\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train the model\n",
    "model = train_model(data_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Evaluation\n",
    "\n",
    "Comprehensive evaluation including accuracy metrics, confusion matrix, and feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_splits):\n",
    "    \"\"\"Comprehensive model evaluation\"\"\"\n",
    "    if model is None or data_splits is None:\n",
    "        return None\n",
    "    \n",
    "    print(\"Evaluating Model...\")\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_val = model.predict(data_splits['X_val'])\n",
    "    y_pred_test = model.predict(data_splits['X_test'])\n",
    "    \n",
    "    # Calculate accuracies\n",
    "    val_accuracy = accuracy_score(data_splits['y_val'], y_pred_val)\n",
    "    test_accuracy = accuracy_score(data_splits['y_test'], y_pred_test)\n",
    "    \n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm_test = confusion_matrix(data_splits['y_test'], y_pred_test)\n",
    "    \n",
    "    # Classification Report\n",
    "    report = classification_report(\n",
    "        data_splits['y_test'], \n",
    "        y_pred_test, \n",
    "        output_dict=True\n",
    "    )\n",
    "    \n",
    "    # Feature Importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': data_splits['X_train'].columns,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    return {\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'confusion_matrix': cm_test,\n",
    "        'classification_report': report,\n",
    "        'feature_importance': feature_importance\n",
    "    }\n",
    "\n",
    "# Evaluate the model\n",
    "model_results = evaluate_model(model, data_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_results is not None:\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(model_results['confusion_matrix'], annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "    plt.title('Confusion Matrix (Test Set)')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_results is not None:\n",
    "    # Classification report\n",
    "    print(\"Classification Report:\")\n",
    "    report_df = pd.DataFrame(model_results['classification_report']).transpose()\n",
    "    display(report_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_results is not None:\n",
    "    # Feature importance\n",
    "    top_features = model_results['feature_importance'].head(10)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.barh(range(len(top_features)), top_features['importance'], color='skyblue')\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.title('Top 10 Feature Importances')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Making Predictions\n",
    "\n",
    "Test the model with sample data and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sample_prediction(model, data_splits, sample_idx=0):\n",
    "    \"\"\"Make prediction on a sample from test set\"\"\"\n",
    "    if model is None or data_splits is None:\n",
    "        return None\n",
    "    \n",
    "    # Select sample from test set\n",
    "    sample_data = data_splits['X_test'].iloc[sample_idx]\n",
    "    true_label = data_splits['y_test'].iloc[sample_idx]\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(sample_data.values.reshape(1, -1))[0]\n",
    "    prediction_proba = model.predict_proba(sample_data.values.reshape(1, -1))[0]\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"Sample {sample_idx + 1} Prediction Results:\")\n",
    "    print(f\"True Label: {int(true_label)}\")\n",
    "    print(f\"Predicted Label: {int(prediction)}\")\n",
    "    print(f\"Result: {'‚úÖ Correct' if prediction == true_label else '‚ùå Incorrect'}\")\n",
    "    print(f\"Prediction Probabilities: {prediction_proba}\")\n",
    "    print(f\"Confidence: {max(prediction_proba):.3f}\")\n",
    "    \n",
    "    # Display sample input data\n",
    "    print(\"\\nSample Input Data:\")\n",
    "    sample_df = pd.DataFrame(sample_data).T\n",
    "    display(sample_df)\n",
    "    \n",
    "    return {\n",
    "        'sample_data': sample_data,\n",
    "        'true_label': true_label,\n",
    "        'prediction': prediction,\n",
    "        'prediction_proba': prediction_proba\n",
    "    }\n",
    "\n",
    "# Make sample predictions\n",
    "if model is not None and data_splits is not None:\n",
    "    print(\"Making sample predictions from test set:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Test first 3 samples\n",
    "    for i in range(min(3, len(data_splits['X_test']))):\n",
    "        result = make_sample_prediction(model, data_splits, i)\n",
    "        print(\"\\n\" + \"-\" * 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model is not None and data_splits is not None:\n",
    "    # Visualize prediction probabilities for a sample\n",
    "    sample_result = make_sample_prediction(model, data_splits, 0)\n",
    "    \n",
    "    if sample_result is not None:\n",
    "        classes = model.classes_\n",
    "        probabilities = sample_result['prediction_proba']\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        bars = plt.bar(classes, probabilities, color=['#ff6b6b', '#4ecdc4'], alpha=0.7)\n",
    "        plt.xlabel('Class')\n",
    "        plt.ylabel('Probability')\n",
    "        plt.title('Prediction Probabilities for Sample 1')\n",
    "        plt.ylim(0, 1)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, prob in zip(bars, probabilities):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                    f'{prob:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Experiment Results (Optional)\n",
    "\n",
    "Save experiment results to database for tracking and comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_experiment_results(db_session, df, data_splits, model, model_results):\n",
    "    \"\"\"Save experiment results to database\"\"\"\n",
    "    if db_session is None:\n",
    "        print(\"Database session not available. Skipping save.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        model_params = {\n",
    "            'max_depth': getattr(model, 'max_depth', None),\n",
    "            'min_samples_split': getattr(model, 'min_samples_split', 2),\n",
    "            'min_samples_leaf': getattr(model, 'min_samples_leaf', 1),\n",
    "            'random_state': getattr(model, 'random_state', None)\n",
    "        }\n",
    "        \n",
    "        experiment = ExperimentRun(\n",
    "            dataset_samples=len(df),\n",
    "            train_samples=len(data_splits['X_train']),\n",
    "            val_samples=len(data_splits['X_val']),\n",
    "            test_samples=len(data_splits['X_test']),\n",
    "            val_accuracy=model_results['val_accuracy'],\n",
    "            test_accuracy=model_results['test_accuracy'],\n",
    "            model_params=json.dumps(model_params),\n",
    "            feature_importance=json.dumps(model_results['feature_importance'].to_dict('records'))\n",
    "        )\n",
    "        \n",
    "        db_session.add(experiment)\n",
    "        db_session.commit()\n",
    "        \n",
    "        print(f\"‚úÖ Experiment saved with ID: {experiment.id}\")\n",
    "        return experiment.id\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save experiment: {str(e)}\")\n",
    "        db_session.rollback()\n",
    "        return None\n",
    "\n",
    "# Save experiment results\n",
    "if (db_session is not None and model is not None and \n",
    "    model_results is not None and data_splits is not None):\n",
    "    experiment_id = save_experiment_results(db_session, df_processed, data_splits, model, model_results)\n",
    "else:\n",
    "    print(\"Skipping experiment save - missing requirements or database not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary Report\n",
    "\n",
    "Generate a comprehensive summary of the ML pipeline results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_report(df, model_results, data_splits):\n",
    "    \"\"\"Generate a comprehensive summary report\"\"\"\n",
    "    if df is None or model_results is None or data_splits is None:\n",
    "        print(\"Cannot generate report - missing data\")\n",
    "        return\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"           HEART DISEASE PREDICTION ML PIPELINE\")\n",
    "    print(\"                    SUMMARY REPORT\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    \n",
    "    print(\"üìä DATASET SUMMARY\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Total Samples: {len(df)}\")\n",
    "    print(f\"Features: {len(df.columns) - 1}\")\n",
    "    print(f\"Target Classes: {df['target'].nunique()}\")\n",
    "    print(f\"Missing Values: {df.isnull().sum().sum()}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"üìà MODEL PERFORMANCE\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Validation Accuracy: {model_results['val_accuracy']:.4f}\")\n",
    "    print(f\"Test Accuracy: {model_results['test_accuracy']:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"üìã DATA SPLITS\")\n",
    "    print(\"-\" * 30)\n",
    "    total_samples = len(data_splits['X_train']) + len(data_splits['X_val']) + len(data_splits['X_test'])\n",
    "    print(f\"Training: {len(data_splits['X_train'])} ({len(data_splits['X_train'])/total_samples*100:.1f}%)\")\n",
    "    print(f\"Validation: {len(data_splits['X_val'])} ({len(data_splits['X_val'])/total_samples*100:.1f}%)\")\n",
    "    print(f\"Test: {len(data_splits['X_test'])} ({len(data_splits['X_test'])/total_samples*100:.1f}%)\")\n",
    "    print()\n",
    "    \n",
    "    print(\"üéØ TOP 5 IMPORTANT FEATURES\")\n",
    "    print(\"-\" * 30)\n",
    "    for i, (_, row) in enumerate(model_results['feature_importance'].head(5).iterrows(), 1):\n",
    "        print(f\"{i}. {row['feature']}: {row['importance']:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"‚úÖ PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# Generate summary report\n",
    "if df_processed is not None and model_results is not None and data_splits is not None:\n",
    "    generate_summary_report(df_processed, model_results, data_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook implemented a complete machine learning pipeline for heart disease prediction, including:\n",
    "\n",
    "1. **Data Loading**: UCI Heart Disease dataset\n",
    "2. **Data Exploration**: Descriptive statistics and visualizations\n",
    "3. **Feature Engineering**: Created cholesterol-to-age ratio feature\n",
    "4. **Data Preprocessing**: Outlier removal and data splitting\n",
    "5. **Model Training**: Decision Tree classifier\n",
    "6. **Model Evaluation**: Comprehensive performance metrics\n",
    "7. **Predictions**: Interactive prediction capabilities\n",
    "8. **Experiment Tracking**: Optional database storage for results\n",
    "\n",
    "The pipeline provides a solid foundation for heart disease prediction and can be extended with additional features, different algorithms, or hyperparameter tuning for improved performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
